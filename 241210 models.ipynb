{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 모델을 생성합니다.\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "# 프롬프트를 생성합니다.\n",
    "prompt = PromptTemplate.from_template(\"{country} 에 대해서 200자 내외로 요약해줘\")\n",
    "\n",
    "# 체인을 생성합니다.\n",
    "chain = prompt | llm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caching: 동일 질문에 대한 답변 저장 후, 활용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국은 동아시아에 위치한 나라로, 서울이 수도이다. 인구는 약 5천만 명으로 밀집된 인구를 가지고 있으며, 경제적으로는 선진국으로 분류된다. 한국은 역사적으로 일본의 식민지였던 경험을 가졌고, 한반도 분단 이후 남한과 북한으로 나뉘어있다. 문화적으로는 한글과 한류 등이 유명하며, 전통적인 음식과 의상도 특징적이다. 한국은 기술과 연구 분야에서도 선진화되어 있으며, K-pop과 K-drama 등 한류 콘텐츠로 세계적으로 인기를 얻고 있다. 현대적인 도시와 전통적인 문화가 공존하는 매력적인 나라이다.\n",
      "CPU times: user 276 ms, sys: 41.5 ms, total: 318 ms\n",
      "Wall time: 2.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache\n",
    "\n",
    "# 인메모리 캐시를 사용합니다.\n",
    "set_llm_cache(InMemoryCache())\n",
    "\n",
    "# 체인을 실행합니다.\n",
    "response = chain.invoke({\"country\": \"한국\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국은 동아시아에 위치한 나라로, 서울이 수도이다. 인구는 약 5천만 명으로 밀집된 인구를 가지고 있으며, 경제적으로는 선진국으로 분류된다. 한국은 역사적으로 일본의 식민지였던 경험을 가졌고, 한반도 분단 이후 남한과 북한으로 나뉘어있다. 문화적으로는 한글과 한류 등이 유명하며, 전통적인 음식과 의상도 특징적이다. 한국은 기술과 연구 분야에서도 선진화되어 있으며, K-pop과 K-drama 등 한류 콘텐츠로 세계적으로 인기를 얻고 있다. 현대적인 도시와 전통적인 문화가 공존하는 매력적인 나라이다.\n",
      "CPU times: user 2.93 ms, sys: 282 µs, total: 3.21 ms\n",
      "Wall time: 3.17 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 체인을 실행합니다.\n",
    "response = chain.invoke({\"country\": \"한국\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 직렬화: parsing 가능한 형태로 저장 및 load 하는 것\n",
    "\n",
    "- dumps: 객체를 JSON 문자열로 직렬화\n",
    "\n",
    "- dumpd: 객체를 딕셔너리로 직렬화\n",
    "\n",
    "-> .pkl 파일로 저장 및 롣,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatOpenAI: True\n",
      "ChatOpenAI: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 프롬프트 템플릿을 사용하여 질문을 생성합니다.\n",
    "prompt = PromptTemplate.from_template(\"{fruit}의 색상이 무엇입니까?\")\n",
    "# 직렬화가 가능한지 체크합니다.\n",
    "print(f\"ChatOpenAI: {ChatOpenAI.is_lc_serializable()}\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# 직렬화가 가능한지 체크합니다.\n",
    "print(f\"ChatOpenAI: {llm.is_lc_serializable()}\")\n",
    "\n",
    "# 체인을 생성합니다.\n",
    "chain = prompt | llm\n",
    "\n",
    "# 직렬화가 가능한지 체크합니다.\n",
    "chain.is_lc_serializable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lc': 1,\n",
       " 'type': 'constructor',\n",
       " 'id': ['langchain', 'schema', 'runnable', 'RunnableSequence'],\n",
       " 'kwargs': {'first': {'lc': 1,\n",
       "   'type': 'constructor',\n",
       "   'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'],\n",
       "   'kwargs': {'input_variables': ['fruit'],\n",
       "    'template': '{fruit}의 색상이 무엇입니까?',\n",
       "    'template_format': 'f-string'},\n",
       "   'name': 'PromptTemplate'},\n",
       "  'last': {'lc': 1,\n",
       "   'type': 'constructor',\n",
       "   'id': ['langchain', 'chat_models', 'openai', 'ChatOpenAI'],\n",
       "   'kwargs': {'model_name': 'gpt-3.5-turbo',\n",
       "    'temperature': 0.0,\n",
       "    'openai_api_key': {'lc': 1, 'type': 'secret', 'id': ['OPENAI_API_KEY']},\n",
       "    'max_retries': 2,\n",
       "    'n': 1},\n",
       "   'name': 'ChatOpenAI'}},\n",
       " 'name': 'RunnableSequence'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.load import dumpd, dumps\n",
    "\n",
    "dumpd_chain = dumpd(chain)\n",
    "dumpd_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"runnable\", \"RunnableSequence\"], \"kwargs\": {\"first\": {\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"prompts\", \"prompt\", \"PromptTemplate\"], \"kwargs\": {\"input_variables\": [\"fruit\"], \"template\": \"{fruit}\\\\uc758 \\\\uc0c9\\\\uc0c1\\\\uc774 \\\\ubb34\\\\uc5c7\\\\uc785\\\\ub2c8\\\\uae4c?\", \"template_format\": \"f-string\"}, \"name\": \"PromptTemplate\"}, \"last\": {\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"chat_models\", \"openai\", \"ChatOpenAI\"], \"kwargs\": {\"model_name\": \"gpt-3.5-turbo\", \"temperature\": 0.0, \"openai_api_key\": {\"lc\": 1, \"type\": \"secret\", \"id\": [\"OPENAI_API_KEY\"]}, \"max_retries\": 2, \"n\": 1}, \"name\": \"ChatOpenAI\"}}, \"name\": \"RunnableSequence\"}'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dumps 함수를 사용하여 직렬화된 체인을 확인합니다.\n",
    "dumps_chain = dumps(chain)\n",
    "dumps_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
