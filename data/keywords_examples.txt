Semantic Search
정의: 의미론적 검색은 사용자의 질의를 단순 키워드 매칭이 아닌 문맥적 의미로 이해하여 관련 결과를 반환하는 검색 방식입니다.
예시: 사용자가 "태양계 행성"을 검색하면 "목성", "화성" 등의 행성 정보를 반환합니다.
연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝

Embedding
정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 벡터 형태로 변환하여 컴퓨터가 의미를 파악할 수 있도록 하는 기술입니다.
예시: "사과"를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.
연관키워드: 자연어 처리, 벡터화, 딥러닝

Token
정의: 토큰은 텍스트를 더 작은 단위로 분할한 최소 처리 단위로, 일반적으로 단어 또는 형태소를 의미합니다.
예시: "나는 학교에 간다"를 "나는", "학교에", "간다"로 분할합니다.
연관키워드: 토큰화, 자연어 처리, 형태소 분석

Language Model
정의: 언어 모델은 주어진 단어나 문장 맥락에서 다음 단어를 예측하거나 확률을 계산하는 모델입니다.
예시: "나는 밥을 ___"에서 "먹었다"를 확률적으로 가장 높은 단어로 선택.
연관키워드: NLP, 확률 모델링, 예측 모델

GPT
정의: GPT(Generative Pre-trained Transformer)는 대규모 텍스트 데이터로 사전 학습한 트랜스포머 기반의 언어 모델입니다.
예시: GPT-3는 다양한 질의에 자연스러운 문장으로 답변을 생성합니다.
연관키워드: 언어모델, 트랜스포머, 사전학습

Transformer
정의: 트랜스포머는 어텐션 메커니즘을 사용하여 시퀀스 내 관계를 효율적으로 파악하는 딥러닝 모델 구조입니다.
예시: BERT, GPT 등의 모델이 Transformer 아키텍처를 기반으로 합니다.
연관키워드: 어텐션, 자연어 처리, 딥러닝 모델

BERT
정의: BERT는 양방향 Transformer 기반 언어 모델로, 문맥 전후 관계를 모두 활용하는 NLP 모델입니다.
예시: 문장 완성, 문장 쌍 관계 추론 등에 활용됩니다.
연관키워드: 사전학습, 마스킹, 문맥 이해

Named Entity Recognition (NER)
정의: NER은 문장 내 인물명, 지명, 기관명 등 특정 개체를 인식하고 태깅하는 작업입니다.
예시: "서울에서 김철수가 스타벅스를 방문했다"에서 "서울(지명)", "김철수(인명)", "스타벅스(기관명)" 추출.
연관키워드: 정보추출, 개체링크, 정보검색

Machine Translation
정의: 기계 번역은 한 언어의 텍스트를 다른 언어로 자동 변환하는 기술입니다.
예시: "Hello"를 "안녕하세요"로 번역.
연관키워드: 번역 모델, Seq2Seq, Transformer

Sentiment Analysis
정의: 감성 분석은 텍스트 내 긍정, 부정, 중립적인 감정을 파악하는 기법입니다.
예시: "이 제품 정말 마음에 든다"는 긍정적인 감성으로 분류.
연관키워드: 감정 분류, 의견 분석, 소비자 피드백

Data Augmentation
정의: 데이터 증강은 기존 데이터에 변형을 가해 새로운 데이터로 만들어 모델 학습을 돕는 기법입니다.
예시: 문장을 동의어로 치환하거나, 단어 순서를 바꿔 새로운 트레이닝 샘플을 만듦.
연관키워드: 오버피팅 방지, 일반화 성능 향상

Vector Database
정의: 벡터 데이터베이스는 벡터 형태로 표현된 데이터(임베딩)를 효율적으로 저장, 검색하는 데이터베이스입니다.
예시: 문장의 임베딩으로 유사한 문서 검색 시 활용.
연관키워드: 벡터 검색, ANN(근사 최근접 탐색), 의미론적 검색

Knowledge Graph
정의: 지식 그래프는 개체와 개체 간 관계를 그래프 형태로 표현한 지식 베이스입니다.
예시: "스티브 잡스-애플 창업자"와 같은 관계를 노드와 엣지로 표현.
연관키워드: 시맨틱 웹, 엔티티 링크, 관계 추론

Text Classification
정의: 텍스트 분류는 문서를 주어진 범주(스팸/햄, 카테고리 등)로 자동 분류하는 기법입니다.
예시: 이메일을 스팸 여부로 분류.
연관키워드: 머신러닝, 라벨링, 분류 모델

Text Summarization
정의: 텍스트 요약은 긴 문서를 짧은 형태로 핵심 내용만 추출하거나 생성하는 NLP 기법입니다.
예시: 긴 뉴스 기사를 2-3줄로 요약.
연관키워드: 추출형 요약, 생성형 요약, 자연어 처리

Question Answering
정의: 질의응답은 사용자의 질문에 대해 텍스트 내에서 답변을 찾아주는 시스템입니다.
예시: "미국의 수도는?" 질문에 "워싱턴 D.C."를 반환.
연관키워드: 정보검색, 독해, NLP

OCR (Optical Character Recognition)
정의: OCR은 이미지에 포함된 문자를 인식하여 디지털 텍스트로 변환하는 기술입니다.
예시: 스캔된 문서에서 텍스트를 추출.
연관키워드: 컴퓨터 비전, 문자인식, 이미지처리

N-gram
정의: N-그램은 연속된 N개의 토큰 시퀀스로 언어모델에서 다음 단어 예측 확률 계산에 활용됩니다.
예시: "나는 학교에 간다"에서 바이그램: ("나는", "학교에"), ("학교에", "간다")
연관키워드: 통계적 언어모델, 확률 모델링

Word2Vec
정의: Word2Vec은 단어를 벡터로 표현하기 위한 신경망 기반 임베딩 기법입니다.
예시: 유사 의미 단어는 벡터 공간에서 가깝게 위치.
연관키워드: 임베딩, 딥러닝, 분포 가설

GloVe
정의: GloVe(Global Vectors)는 단어공간에서 전역 통계 정보를 활용해 단어 벡터를 학습하는 임베딩 기법입니다.
예시: "king" - "man" + "woman" ≈ "queen"과 같은 벡터 연산 가능.
연관키워드: 임베딩, 통계기반, 단어 의미

FastText
정의: FastText는 단어를 n-gram 단위로 분해하여 희귀 단어에 대한 일반화를 개선한 임베딩 기법입니다.
예시: "character"를 "char", "hara", "arac" 등 subword로 분해해 학습.
연관키워드: 서브워드, 임베딩, OOV 문제

Hugging Face
정의: Hugging Face는 다양한 NLP 모델과 데이터셋을 공유하는 플랫폼 및 라이브러리입니다.
예시: Transformers 라이브러리를 통해 BERT, GPT 계열 모델 활용 가능.
연관키워드: 모델 허브, 오픈소스, 커뮤니티

LangChain
정의: LangChain은 LLM 기반 애플리케이션 개발을 위한 프레임워크로, 체이닝, 메모리, 에이전트 등의 개념을 제공.
예시: LLM에 툴을 연결해 복잡한 질의 응답.
연관키워드: LLM, 에이전트, MLOps

OpenAI
정의: OpenAI는 GPT 계열 모델 등 선도적인 AI 연구 및 제품을 개발하는 조직입니다.
예시: GPT-4 모델을 사용한 ChatGPT 서비스.
연관키워드: 인공지능 연구, 대규모 언어 모델, API

Fine-tuning
정의: 파인튜닝은 사전학습된 모델을 특정 태스크에 맞춰 추가 학습하는 과정입니다.
예시: GPT-3를 특정 도메인 질의응답 태스크로 파인튜닝.
연관키워드: 전이학습, 사전학습, 맞춤 모델

Prompt Engineering
정의: 프롬프트 엔지니어링은 LLM에게 원하는 답변을 이끌어내기 위해 질의 형식을 설계하는 과정입니다.
예시: “다음 문장을 요약해줘:”와 같은 지시문으로 LLM 결과 제어.
연관키워드: LLM, 질의 최적화, 사용자 가이드

Zero-shot Learning
정의: 제로샷 학습은 라벨이 없는 새로운 클래스나 도메인에 대해 사전지식만으로 추론하는 방법입니다.
예시: 한 번도 본 적 없는 개체를 유사 개념과 연관 지어 분류.
연관키워드: 일반화, 전이학습, 사전학습

One-shot Learning
정의: 원샷 학습은 라벨이 있는 예시 하나만으로 새로운 클래스를 학습하는 능력입니다.
예시: 이미지 한 장만으로 새로운 카테고리를 인식.
연관키워드: 소량 학습, 전이학습, 유추

Few-shot Learning
정의: 퓨샷 학습은 소수의 라벨된 예시로도 모델이 새 클래스를 이해하도록 하는 학습법입니다.
예시: 5~10개 예시만 주어도 분류기 가동.
연관키워드: 소량 데이터, 전이학습, 일반화

Attention Mechanism
정의: 어텐션은 입력 시퀀스의 특정 부분에 가중치를 두어 모델이 중요한 정보에 초점을 맞추도록 하는 기법입니다.
예시: 번역 시 문장 내 특정 단어에 주목.
연관키워드: Transformer, 중요도 할당, 시퀀스 처리

Pretraining
정의: 사전학습은 대규모 비라벨 데이터로 모델을 학습해 언어적/문맥적 이해 능력을 미리 습득하는 과정입니다.
예시: BERT는 대량의 텍스트로 마스킹된 언어 모델링 사전학습.
연관키워드: 비지도 학습, 전이학습, 파운데이션 모델

Finetuning
정의: 파인튜닝은 사전학습된 모델을 특정 태스크용 라벨 데이터로 추가 학습하는 과정입니다.
예시: 사전학습된 BERT를 감성 분석 태스크로 파인튜닝.
연관키워드: 전이학습, 태스크 특화, 모델 조정

Self-supervised Learning
정의: 자기 지도 학습은 라벨 없이 입력 데이터 자체에서 학습 신호를 얻는 방법입니다.
예시: 문장 일부를 마스킹하고 나머지로 예측.
연관키워드: 비지도 학습, 대규모 사전학습, 특징 추출

Contrastive Learning
정의: 대조 학습은 유사한 샘플은 가깝게, 다른 샘플은 멀리 배치하는 임베딩 학습 기법입니다.
예시: 같은 이미지 변형끼리는 벡터 공간에서 가깝게, 다른 이미지와는 멀게.
연관키워드: 표현학습, 임베딩, 클러스터링

Multimodal
정의: 멀티모달은 텍스트, 이미지, 오디오 등 다양한 형태의 데이터를 통합하여 처리하는 기술입니다.
예시: 이미지 캡셔닝, 이미지+텍스트 질의응답.
연관키워드: 멀티모달 모델, 융합, 비주얼-언어 처리

Reinforcement Learning
정의: 강화학습은 에이전트가 환경과 상호작용하면서 보상을 최대화하는 행동을 학습하는 기법입니다.
예시: 바둑 게임에서 보상(승리)을 최대화하는 수를 학습.
연관키워드: 에이전트, 보상, 정책 탐색

Chain-of-thought
정의: 생각의 사슬(chain-of-thought)은 LLM이 답변을 생성하기 전에 내부적으로 논리적 추론 과정을 거치는 개념입니다.
예시: 복잡한 수학 문제 풀이 전에 단계별 논리 전개.
연관키워드: 추론, 프로세스, 해설

Hallucination
정의: LLM이 존재하지 않는 정보나 사실을 단정적으로 생성하는 현상을 의미합니다.
예시: 질문에 실제로 없는 인물, 사실을 답변.
연관키워드: 거짓 정보, 사실성 검증, 신뢰성 문제

Retrieval Augmented Generation (RAG)
정의: RAG는 외부 지식베이스에서 정보를 검색 후 LLM 생성 과정에 반영하는 기법입니다.
예시: 질문에 대한 답을 벡터DB에서 가져와 문장 생성.
연관키워드: 검색+생성, 지식 혼합, LLM 성능 향상

Pydantic
정의: Pydantic은 Python 데이터 검증 및 설정 관리를 위한 라이브러리로, 타입 힌트를 활용해 구조화된 데이터를 처리합니다.
예시: JSON으로 받은 데이터를 Pydantic 모델로 검증.
연관키워드: 데이터 검증, 스키마 정의, Python

Vector Index
정의: 벡터 인덱스는 임베딩된 벡터를 효율적으로 검색하기 위한 데이터 구조입니다.
예시: 문장 임베딩을 벡터 인덱스에 저장하고, 유사 질의 탐색.
연관키워드: ANN, 벡터 검색, 의미 기반 검색

Context Window
정의: 컨텍스트 윈도우는 LLM이 한 번에 처리할 수 있는 최대 토큰 길이(문맥 범위)를 의미합니다.
예시: GPT-3.5는 약 4,000 토큰 내에서 문맥 유지 가능.
연관키워드: 최대 시퀀스 길이, 문맥 유지, 토큰 제한

Tokenization
정의: 토크나이제이션은 텍스트를 모델이 처리하기 쉬운 토큰 단위로 분할하는 과정입니다.
예시: "Hello world!"를 ["Hello", "world", "!"]로 토큰화.
연관키워드: 전처리, NLP, 형태소 분석

Language Modeling
정의: 언어 모델링은 단어나 문장 시퀀스에 대해 확률 분포를 학습하는 과정입니다.
예시: 주어진 단어열 다음에 올 단어의 확률 예측.
연관키워드: NLP, 확률 모델, 시퀀스 예측

Coherence
정의: 응집성은 문장이나 문단 내 문맥적 일관성을 가리킵니다.
예시: "나는 밥을 먹고, 학교에 갔다"는 논리적 흐름이 있음.
연관키워드: 문맥 일관성, 의미 연결성

Perplexity
정의: 퍼플렉시티는 언어 모델의 성능을 측정하는 지표로, 모델이 샘플을 예측하는 데 얼마나 불확실한지 나타냅니다.
예시: 낮은 퍼플렉시티일수록 모델이 문맥 예측을 잘함.
연관키워드: 모델 평가, 언어모델 품질

LLM (Large Language Model)
정의: LLM은 대규모 파라미터를 가진 언어모델로, 복잡한 자연어 처리 태스크를 수행할 수 있습니다.
예시: GPT-4, PaLM과 같은 모델.
연관키워드: 대규모 사전학습, 범용 NLP, 강화학습

RLHF (Reinforcement Learning from Human Feedback)
정의: RLHF는 인간 피드백을 활용한 강화학습으로 모델 출력을 개선하는 기법입니다.
예시: ChatGPT가 사용자의 선호도에 맞춰 답변 품질 개선.
연관키워드: 사용자 피드백, 정책 학습, 모델 개선

Causal Language Model
정의: 인과 언어 모델은 이전 토큰들을 기반으로 다음 토큰 예측을 수행하는 언어 모델입니다.
예시: GPT 계열 모델은 대체로 인과적 언어모델로 동작.
연관키워드: 시퀀스 예측, 단방향 모델, 오토리그레시브

Batch Normalization
정의: 배치 정규화는 신경망 훈련 시 각 배치별로 입력을 정규화하여 학습을 안정시키는 기법입니다.
예시: ResNet 등의 CV모델에 활용, NLP 모델에도 적용 가능.
연관키워드: 딥러닝, 안정적 학습, 가속 학습

Overfitting
정의: 오버피팅은 모델이 학습 데이터에 과적합하여 새로운 데이터에 일반화 성능이 떨어지는 현상입니다.
예시: 훈련 정확도는 99%인데 검증 정확도는 60%로 급락.
연관키워드: 일반화, 규제화, 모델 튜닝

Generalization
정의: 일반화는 모델이 훈련 데이터 외의 새로운 데이터에도 잘 대응하는 능력을 의미합니다.
예시: unseen 데이터에도 정확한 예측 가능.
연관키워드: 모델 성능, 검증, 테스트

Cross-validation
정의: 교차검증은 데이터를 여러 폴드로 나눠 반복적으로 학습/검증하여 모델의 일반화 능력을 평가하는 기법입니다.
예시: K-Fold 교차검증으로 평균 성능 평가.
연관키워드: 모델 평가, 데이터 분할, 일반화

Regularization
정의: 정규화는 모델 복잡도를 줄여 오버피팅을 완화하는 기법입니다.
예시: L2 정규화를 통해 가중치 크기 제한.
연관키워드: 일반화, 오버피팅 방지, 하이퍼파라미터
